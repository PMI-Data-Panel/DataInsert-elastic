import pandas as pd
from fastapi import FastAPI, HTTPException
from elasticsearch import Elasticsearch
from elasticsearch.helpers import bulk
import datetime
from sentence_transformers import SentenceTransformer
import os
import re
import traceback
import json

# --- ëª¨ë¸ ë° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ---
embedding_model = SentenceTransformer("nlpai-lab/KURE-v1")
VECTOR_DIMENSIONS = 1024

# --- FastAPI ë° Elasticsearch ì´ˆê¸°í™” ---
app = FastAPI()
es = Elasticsearch("http://localhost:9200")


def create_index_if_not_exists(index_name: str):
    """
    Elasticsearchì— íŠ¹ì • ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´, ìƒˆ ì¸ë±ìŠ¤ë¥¼ ìƒì„±.
    """
    
    #í•´ë‹¹ ì´ë¦„ì˜ ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not es.indices.exists(index=index_name):
        print(f"âœ¨ '{index_name}' ì¸ë±ìŠ¤ê°€ ì—†ì–´ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

        mappings = {
            "properties": {
                "user_id": {"type": "keyword"}, # ì‚¬ìš©ì ID
                "timestamp": {"type": "date"},
                "qa_pairs": { 
                    "type": "nested", # ì§ˆë¬¸-ì‘ë‹µ ìŒë“¤ì„ ë…ë¦½ì ì¸ ê°ì²´ ë°°ì—´ë¡œ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ íƒ€ì…
                    "properties": {
                        "q_code": {"type": "keyword"}, # ì§ˆë¬¸ ì½”ë“œ (ì˜ˆ: 'Q1', 'Q5_1')
                        "q_text": {"type": "text", "analyzer": "nori"}, # ì§ˆë¬¸ í…ìŠ¤íŠ¸
                        "q_type": {"type": "keyword"},  # ì§ˆë¬¸ ìœ í˜• (ì˜ˆ: 'SINGLE', 'MULTI')
                        "answer_text": {"type": "text", "analyzer": "nori"}, # ë‹µë³€ í…ìŠ¤íŠ¸
                        "embedding_text": {
                            "type": "text",
                            "analyzer": "nori",
                            "index": False, # ì„ë² ë”© ìƒì„±ì—ë§Œ ì‚¬ìš©, ê²€ìƒ‰ ëŒ€ìƒì—ì„œëŠ” ì œì™¸í•˜ì—¬ ì €ì¥ ê³µê°„ ì ˆì•½
                        },
                        "answer_vector": {
                            "type": "dense_vector", # ë²¡í„° ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ íƒ€ì…
                            "dims": VECTOR_DIMENSIONS,
                        },
                    },
                },
            }
        }
        try:
            # ì •ì˜ëœ ë§¤í•‘ìœ¼ë¡œ ìƒˆë¡œìš´ ì¸ë±ìŠ¤ë¥¼ ìƒì„±
            es.indices.create(index=index_name, mappings=mappings)
            print(f"ğŸ‘ '{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
        except Exception as e:
            # ì¸ë±ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ 500 ì„œë²„ ì˜¤ë¥˜ë¥¼ ë°œìƒ
            raise HTTPException(
                status_code=500, detail=f"'{index_name}' ì¸ë±ìŠ¤ ìƒì„± ì‹¤íŒ¨: {e}"
            )
            
            
# --- 4. ì§ˆë¬¸ ë©”íƒ€ë°ì´í„° íŒŒì‹± í•¨ìˆ˜ ---
def parse_question_metadata(file_path: str) -> dict:
    """
    csv íŒŒì¼ì„ ì½ì–´, ê° ì§ˆë¬¸ ì½”ë“œì— ëŒ€í•œ ì •ë³´(ì§ˆë¬¸ ë‚´ìš©, ìœ í˜•, ì„ íƒì§€)ë¥¼
    ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ê°€ê³µí•˜ì—¬ ë°˜í™˜.
    """
    metadata = {} # ëª¨ë“  ì§ˆë¬¸ ì •ë³´ë¥¼ ë‹´ì„ ë¹ˆ ë”•ì…”ë„ˆë¦¬
    current_q_code = None # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸ ì½”ë“œë¥¼ ì¶”ì í•˜ê¸° ìœ„í•œ ë³€ìˆ˜
    with open(file_path, "r", encoding="utf-8-sig") as f:
        for line in f:  
            line = line.strip() # ê° ì¤„ì˜ ì•ë’¤ ê³µë°± ì œê±°
            if not line:  # ë¹ˆ ì¤„ì´ë©´ ê±´ë„ˆë›°ê¸°.
                continue
            
            # ì •ê·œí‘œí˜„ì‹ì„ ì‚¬ìš©í•˜ì—¬ "ì½”ë“œ,í…ìŠ¤íŠ¸,íƒ€ì…" í˜•ì‹ì˜ ìƒˆë¡œìš´ ì§ˆë¬¸ í–‰
            match = re.match(r"^([a-zA-Z0-9_]+),([^,]+),([^,]+)$", line)
            if match:
                
                # ë§¤ì¹­ì— ì„±ê³µí•˜ë©´, ê·¸ë£¹ìœ¼ë¡œ ë‚˜ëˆ  ê° ë³€ìˆ˜ì— í• ë‹¹í•©ë‹ˆë‹¤.
                q_code, q_text, q_type = match.groups()
                current_q_code = q_code.strip() # í˜„ì¬ ì§ˆë¬¸ ì½”ë“œë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
                # ë©”íƒ€ë°ì´í„° ë”•ì…”ë„ˆë¦¬ì— í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ì •ë³´ë¥¼ ì €ì¥í•  ìƒˆë¡œìš´ í•­ëª©ì„ ë§Œë“­ë‹ˆë‹¤.
                metadata[current_q_code] = {
                    "text": q_text.strip(),
                    "type": q_type.strip(),
                    "options": {}, # ì´ ì§ˆë¬¸ì— ëŒ€í•œ ì„ íƒì§€ë“¤ì„ ì €ì¥í•  ë¹ˆ ë”•ì…”ë„ˆë¦¬
                }
            # ìˆ«ìë¡œ ì‹œì‘í•˜ê³  ì½¤ë§ˆê°€ ìˆëŠ” í–‰ì€ ì´ì „ ì§ˆë¬¸ì— ëŒ€í•œ ì„ íƒì§€(ì˜µì…˜) í–‰ìœ¼ë¡œ ê°„ì£¼
            elif current_q_code and re.match(r"^\d+,", line):
                parts = line.split(",", 2)  # ì½¤ë§ˆë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìµœëŒ€ 2ë²ˆë§Œ ë¶„ë¦¬
                option_code = parts[0].strip()
                option_text = parts[1].strip()
                if option_code: # ì„ íƒì§€ ì½”ë“œê°€ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´
                    # í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ì§ˆë¬¸ì˜ 'options' ë”•ì…”ë„ˆë¦¬ì— ì„ íƒì§€ ì •ë³´ë¥¼ ì¶”ê°€
                    metadata[current_q_code]["options"][option_code] = option_text
    return metadata

# --- 5. FastAPI ë¼ìš°íŠ¸(API ì—”ë“œí¬ì¸íŠ¸) ì •ì˜ ---
@app.get("/")
def read_root():
    return {"message": "FAST APIì„œë²„ ì‹¤í–‰ ì¤‘"}


@app.post("/index-survey-data") 
def index_survey_data_by_user():
    """
    ì„¤ë¬¸ ë°ì´í„° ì „ì²´ë¥¼ ìƒ‰ì¸í•˜ëŠ” ë©”ì¸ ë¡œì§ ì‹¤í–‰.
    """
    question_file = "./data/question_list.csv" # ì§ˆë¬¸ ëª©ë¡ íŒŒì¼ ê²½ë¡œ
    response_file = "./data/response_list_300.csv" # ì‘ë‹µ ë°ì´í„° íŒŒì¼ ê²½ë¡œ
    index_name = "survey_responses" # ì‚¬ìš©í•  ì¸ë±ìŠ¤ ì´ë¦„

    try:
        # Elasticsearch ì„œë²„ê°€ í™œì„± ìƒíƒœì¸ì§€ í™•ì¸
        if not es.ping():
            raise HTTPException(
                status_code=503, detail="Elasticsearch ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            )

        print("\n--- ğŸš€ ë°ì´í„° ìƒ‰ì¸ ì‘ì—… ì‹œì‘")
        print(f"- ëŒ€ìƒ ì¸ë±ìŠ¤: {index_name}\n")
        
        # ë§Œì•½ ì¸ë±ìŠ¤ê°€ ì´ë¯¸ ì¡´ì¬í•œë‹¤ë©´ ì‚­ì œ
        if es.indices.exists(index=index_name):
            es.indices.delete(index=index_name)
            print(f"ğŸ—‘ï¸  ê¸°ì¡´ '{index_name}' ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.")
        
        # ì¸ë±ìŠ¤ ìƒì„± í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ ì¸ë±ìŠ¤ ìƒì„±
        create_index_if_not_exists(index_name)

        # ì§ˆë¬¸ ë©”íƒ€ë°ì´í„° íŒŒì¼ì„ íŒŒì‹±í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ
        questions_meta = parse_question_metadata(question_file)
        print("âœ… ì§ˆë¬¸ ë©”íƒ€ë°ì´í„° íŒŒì‹± ì™„ë£Œ.")

        df_responses = pd.read_csv(response_file, encoding="utf-8-sig")
        
        # pandasì˜ ê²°ì¸¡ê°’(NaN)ì„ íŒŒì´ì¬ì˜ None ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ ì¼ê´€ì„±ì„ ìœ ì§€
        df_responses = df_responses.astype(object).where(pd.notnull(df_responses), None)
        print(f"âœ… ì‘ë‹µ ë°ì´í„° ë¡œë“œ ì™„ë£Œ. (ì´ {len(df_responses)}ëª…)")

        actions = [] # Elasticsearch bulk APIì— ì‚¬ìš©í•  ì‘ì—…ë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
        user_count = 0 # ì²˜ë¦¬ ì¤‘ì¸ ì‚¬ìš©ì ìˆ˜ë¥¼ ì„¸ê¸° ìœ„í•œ ë³€ìˆ˜
        total_users = len(df_responses) # ì „ì²´ ì‚¬ìš©ì ìˆ˜

        # ë°ì´í„°í”„ë ˆì„ì˜ í•œ í–‰(row)ì”©, ì¦‰ ì‚¬ìš©ì í•œ ëª…ì”© ìˆœíšŒ
        for _, row in df_responses.iterrows():
            user_count += 1
            
            # 10ëª… ë‹¨ìœ„, ì²« ë²ˆì§¸, ë§ˆì§€ë§‰ ì‚¬ìš©ìì— ëŒ€í•´ ì§„í–‰ ìƒí™©ì„ ì¶œë ¥
            if user_count % 10 == 0 or user_count == 1 or user_count == total_users:
                print(f"ğŸ”„ ì‚¬ìš©ì ë°ì´í„° ì²˜ë¦¬ ì¤‘... ({user_count}/{total_users})")

            user_id = row.get("mb_sn")
            if not user_id:
                continue

            # í•´ë‹¹ ì‚¬ìš©ìì˜ ëª¨ë“  ì§ˆë¬¸-ì‘ë‹µ ìŒì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸
            all_qa_pairs_for_user = []

            # ì‚¬ìš©ìì˜ ê° ì‘ë‹µ(ì»¬ëŸ¼)ì„ ìˆœíšŒ
            for q_code, raw_answer in row.items():

                # 'mb_sn' ì»¬ëŸ¼ì´ê±°ë‚˜ ì‘ë‹µ ê°’ì´ ì—†ìœ¼ë©´ ì²˜ë¦¬x
                if q_code == "mb_sn" or raw_answer is None:
                    continue
                
                # ì§ˆë¬¸ ë©”íƒ€ë°ì´í„°ì—ì„œ í˜„ì¬ ì§ˆë¬¸ ì½”ë“œ(q_code)ì— ëŒ€í•œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                q_info = questions_meta.get(q_code)
                if not q_info:
                    continue
                
                # ì§ˆë¬¸ í…ìŠ¤íŠ¸ì™€ ìœ í˜• ê°€ì ¸ì˜¤ê¸°
                q_text, q_type = q_info["text"], q_info["type"]
                # ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸ë“¤ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
                answers_text_list = []

                # ì§ˆë¬¸ ìœ í˜•ì´ 'MULTI'(ë‹¤ì¤‘ ì‘ë‹µ)ì¸ ê²½ìš°
                if q_type == "MULTI":
                    # ì‘ë‹µ ë¬¸ìì—´ì„ ì½¤ë§ˆ(,)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ì½”ë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
                    answer_codes = str(raw_answer).split(",")
                    for code in answer_codes:
                        code = code.strip()
                        if code: # ì½”ë“œê°€ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´
                            
                            # ë©”íƒ€ë°ì´í„°ì˜ 'options'ì—ì„œ ì½”ë“œì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ ì¶”ê°€
                            # ë§Œì•½ í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ "ì—†ëŠ” ì½”ë“œ"ë¼ê³  í‘œì‹œ
                            answers_text_list.append(
                                q_info["options"].get(code, f"ì—†ëŠ” ì½”ë“œ: {code}")
                            )
                            
                # ì§ˆë¬¸ ìœ í˜•ì´ 'SINGLE'(ë‹¨ì¼ ì‘ë‹µ)ì¸ ê²½ìš°
                elif q_type == "SINGLE":
                    # ì‘ë‹µ ì½”ë“œì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ë¥¼ ì°¾ì•„ ì¶”ê°€

                    # ë§Œì•½ í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì›ë˜ ì‘ë‹µê°’(raw_answer)ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©. (ì£¼ê´€ì‹ ì‘ë‹µ ë“±)
                    answers_text_list.append(
                        q_info["options"].get(str(raw_answer).strip(), raw_answer)
                    )

                # ê·¸ ì™¸ ìœ í˜•(ì˜ˆ: Numeric, String)ì€ ì‘ë‹µê°’ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
                else:
                    answers_text_list.append(str(raw_answer))

                # ê° ë‹µë³€ í…ìŠ¤íŠ¸ë¥¼ nested ê°ì²´ë¡œ ë³€í™˜
                for answer_text in answers_text_list:
                    # ë‹µë³€ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì²˜ë¦¬x.
                    if answer_text is None or str(answer_text).strip() == "":
                        continue
                    
                    
                    embedding_text = f"{q_text} ì§ˆë¬¸ì— '{answer_text}'ë¼ê³  ë‹µë³€"
                    vector = embedding_model.encode(embedding_text).tolist()

                    # Elasticsearchì˜ nested í•„ë“œì— ì €ì¥ë  í•˜ë‚˜ì˜ ì§ˆë¬¸-ì‘ë‹µ ê°ì²´ë¥¼ ìƒì„±
                    qa_pair_doc = {
                        "q_code": q_code,
                        "q_text": q_text,
                        "q_type": q_type,
                        "answer_text": answer_text,
                        "embedding_text": embedding_text,
                        "answer_vector": vector,
                    }
                    all_qa_pairs_for_user.append(qa_pair_doc)

            # ì²˜ë¦¬ëœ ì§ˆë¬¸-ì‘ë‹µ ìŒì´ ìˆì„ ê²½ìš°ì—ë§Œ ìµœì¢… ì‚¬ìš©ì ë¬¸ì„œë¥¼ ìƒì„±
            if all_qa_pairs_for_user:
                final_user_document = {
                    "user_id": user_id,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "qa_pairs": all_qa_pairs_for_user,
                }
                actions.append(
                    {"_index": index_name, "_id": user_id, "_source": final_user_document}
                )

        if not actions:
            print("âš ï¸  ì²˜ë¦¬í•  ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤. ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            return {"message": "ì²˜ë¦¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        print(
            f"\nâœ… ì´ {len(actions)}ê°œì˜ ë¬¸ì„œë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. (ì‚¬ìš©ì ë‹¨ìœ„ë¡œ ê·¸ë£¹í™”)"
        )
        print("--- ğŸ“„ ì²« ë²ˆì§¸ ì‚¬ìš©ì ë¬¸ì„œ ìƒ˜í”Œ ---")
        print(json.dumps(actions[0]["_source"], indent=2, ensure_ascii=False))
        print("--------------------------------\n")

        print("â³ Elasticsearchì— ë°ì´í„° ëŒ€ëŸ‰ ì‚½ì…(bulk)ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        success, failed = bulk(es, actions, raise_on_error=False, refresh=True)

        print(f"ğŸ‰ ì‘ì—… ì™„ë£Œ! ì„±ê³µ: {success}, ì‹¤íŒ¨: {len(failed)}")

        return {
            "message": "ë°ì´í„° ìƒ‰ì¸ ì‘ì—… ì™„ë£Œ.",
            "ì„±ê³µ": success,
            "ì‹¤íŒ¨": len(failed),
        }

    except Exception as e:
        print("ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ")
        traceback.print_exc()
        raise HTTPException(
            status_code=500, detail=f"ì²˜ë¦¬ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )